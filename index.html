<!DOCTYPE html>
<html lang="en-US">

<head>

</head>

<body>
    <div class="wrapper">
        <header>
            <h1><a href="https://aframires.github.io/stylegan2-ada-pytorch/">Supervised and Unsupervised Discovery of Latent Directions for Drum Synthesi</a></h1>


            <p class="view"><a href="https://github.com/aframires/stylegan2-ada-pytorch">View the source code on GitHub
                    <small>aframires/stylegan2-ada-pytorch</small></a></p>





        </header>
        <section>

            <h2 id="loopnet-musical-loop-synthsis-conditioned-on-intuitive-musical-parameters">LoopNet: Musical Loop
                Synthsis Conditioned on Intuitive Musical Parameters</h2>

            <h3 id="pritish-chandna-ant贸nio-ramires-xavier-serra-emilia-g贸mez">Pritish Chandna, Ant贸nio Ramires, Xavier
                Serra, Emilia G贸mez</h3>

            <p>On this website, we present audio examples of our drum loop synthesis models. The code to replicate these
                results is available at our <a href="https://github.com/aframires/drum-loop-synthesis">Github
                    Repository</a>, and an interactive Jupyter Notebook is available at <a
                    href="https://colab.research.google.com/github/aframires/drum-loop-synthesis/blob/main/LOOPNET.ipynb">Google
                    Colab</a></p>

            <h3 id="reconstruction-of-sounds-from-the-test-set">Reconstruction of sounds from the test set</h3>
            <p>In this section, we show how the different models behave when recreating loops from the test set. These
                loops were not included in the training of the models.</p>

        </section>
<footer>

    <p>This project is maintained by <a href="https://github.com/aframires">aframires</a></p>

    <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small>
    </p>
</footer>
</div>
<script src="/drum-loop-synthesis/assets/js/scale.fix.js"></script>

</body>

</html>